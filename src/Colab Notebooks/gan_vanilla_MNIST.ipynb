{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"gan_vanilla_MNIST.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"metadata":{"id":"ACyOWcWDM3X0","colab_type":"code","colab":{}},"cell_type":"code","source":["import tensorflow as tf\n","from tensorflow.examples.tutorials.mnist import input_data\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import matplotlib.gridspec as gridspec\n","import os"],"execution_count":0,"outputs":[]},{"metadata":{"id":"kgozLB5EM5CV","colab_type":"code","colab":{}},"cell_type":"code","source":["# define D / G\n","X = tf.placeholder(tf.float32, shape=[None, 784])\n","\n","D_W1 = tf.get_variable(name=\"D_W1\", shape=[784, 128], initializer=tf.contrib.layers.xavier_initializer())\n","D_b1 = tf.Variable(tf.zeros(shape=[128]))\n","\n","D_W2 = tf.get_variable(name=\"D_W2\", shape=[128, 1], initializer=tf.contrib.layers.xavier_initializer())\n","D_b2 = tf.Variable(tf.zeros(shape=[1]))\n","\n","theta_D = [D_W1, D_W2, D_b1, D_b2]\n","\n","\n","Z = tf.placeholder(tf.float32, shape=[None, 100])\n","\n","G_W1 = tf.get_variable(name=\"G_W1\", shape=[100, 128], initializer=tf.contrib.layers.xavier_initializer())\n","G_b1 = tf.Variable(tf.zeros(shape=[128]))\n","\n","G_W2 = tf.get_variable(name=\"G_W2\", shape=[128, 784], initializer=tf.contrib.layers.xavier_initializer())\n","G_b2 = tf.Variable(tf.zeros(shape=[784]))\n","\n","theta_G = [G_W1, G_W2, G_b1, G_b2]"],"execution_count":0,"outputs":[]},{"metadata":{"id":"FNprrMHxM8h0","colab_type":"code","colab":{}},"cell_type":"code","source":["def sample_Z(m, n):\n","    return np.random.uniform(-1., 1., size=[m, n])\n","\n","\n","def generator(z):\n","    G_h1 = tf.nn.relu(tf.matmul(z, G_W1) + G_b1)\n","    G_log_prob = tf.matmul(G_h1, G_W2) + G_b2\n","    G_prob = tf.nn.sigmoid(G_log_prob)\n","\n","    return G_prob\n","\n","\n","def discriminator(x):\n","    D_h1 = tf.nn.relu(tf.matmul(x, D_W1) + D_b1)\n","    D_logit = tf.matmul(D_h1, D_W2) + D_b2\n","    D_prob = tf.nn.sigmoid(D_logit)\n","\n","    return D_prob, D_logit\n","\n","\n","def plot(samples):\n","    fig = plt.figure(figsize=(4, 4))\n","    gs = gridspec.GridSpec(4, 4)\n","    gs.update(wspace=0.05, hspace=0.05)\n","\n","    for i, sample in enumerate(samples):\n","        ax = plt.subplot(gs[i])\n","        plt.axis('off')\n","        ax.set_xticklabels([])\n","        ax.set_yticklabels([])\n","        ax.set_aspect('equal')\n","        plt.imshow(sample.reshape(28, 28), cmap='Greys_r')\n","\n","    return fig"],"execution_count":0,"outputs":[]},{"metadata":{"id":"1NdgGyxoM900","colab_type":"code","colab":{}},"cell_type":"code","source":["# generator/discriminator\n","G_sample = generator(Z)\n","D_real, D_logit_real = discriminator(X)\n","D_fake, D_logit_fake = discriminator(G_sample)\n","\n","# losses\n","D_loss_real = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=D_logit_real, labels=tf.ones_like(D_logit_real)))\n","D_loss_fake = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=D_logit_fake, labels=tf.zeros_like(D_logit_fake)))\n","D_loss = D_loss_real + D_loss_fake\n","G_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=D_logit_fake, labels=tf.ones_like(D_logit_fake)))\n","\n","D_solver = tf.train.AdamOptimizer().minimize(D_loss, var_list=theta_D)\n","G_solver = tf.train.AdamOptimizer().minimize(G_loss, var_list=theta_G)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Hp0stVmeM-6M","colab_type":"code","colab":{}},"cell_type":"code","source":["# batch size\n","mb_size = 128\n","Z_dim = 100\n","\n","# MNIST load\n","mnist = input_data.read_data_sets('../../MNIST_data', one_hot=True)\n","\n","# session\n","sess = tf.Session()\n","sess.run(tf.global_variables_initializer())\n","\n","# make output dir\n","if not os.path.exists('out/'):\n","    os.makedirs('out/')\n","\n","cwd_dir = os.getcwd()\n","print(cwd_dir)\n","list_cwd = os.listdir(cwd_dir)\n","print(list_cwd)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"TjgBp6cWM_7r","colab_type":"code","colab":{}},"cell_type":"code","source":["i = 0\n","\n","for it in range(100000):\n","    if it % 1000 == 0:\n","        samples = sess.run(G_sample, feed_dict={Z: sample_Z(16, Z_dim)})\n","\n","        fig = plot(samples)\n","        plt.savefig('out/{}.png'.format(str(i).zfill(3)), bbox_inches='tight')\n","        i += 1\n","        plt.close(fig)\n","\n","    X_mb, _ = mnist.train.next_batch(mb_size)\n","\n","    _, D_loss_curr = sess.run([D_solver, D_loss], feed_dict={X: X_mb, Z: sample_Z(mb_size, Z_dim)})\n","    _, G_loss_curr = sess.run([G_solver, G_loss], feed_dict={Z: sample_Z(mb_size, Z_dim)})\n","\n","    if it % 1000 == 0:\n","        print('Iter: {}'.format(it))\n","        print('D loss: {:.4}'. format(D_loss_curr))\n","        print('G_loss: {:.4}'.format(G_loss_curr))\n","        print()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"a6I6hVCVNBCL","colab_type":"code","colab":{}},"cell_type":"code","source":["#change dir to out\n","out_dir = os.path.join(cwd_dir, \"out\")\n","print(out_dir)\n","\n","from PIL import Image\n","\n","# plot\n","list_out = os.listdir(out_dir)\n","img_list = []\n","for i in list_out:\n","  img_path = os.path.join(out_dir, i)\n","  img = Image.open(img_path)\n","  img_list.append(img)\n","  print(i)\n","  imgplot = plt.imshow(img)"],"execution_count":0,"outputs":[]}]}